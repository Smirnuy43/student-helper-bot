import asyncio
import logging
import os
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message
from aiogram.enums.parse_mode import ParseMode
from aiogram.fsm.storage.memory import MemoryStorage
from dotenv import load_dotenv
from file_processor.parser import download_file, extract_text_from_file
from prompt_constructor.constructor import build_prompt
from gpt_engine.client import get_chatgpt_response
from bot.handlers import start
from aiogram import Router
from bot.handlers.start import UserState
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup


# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ .env
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞
bot = Bot(token=BOT_TOKEN, parse_mode=ParseMode.MARKDOWN)
dp = Dispatcher(storage=MemoryStorage())

router = Router()
router.include_routers(start.router)

dp.include_router(router)

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ===
@dp.message(UserState.waiting_for_task, lambda m: m.text is not None)
async def handle_text(message: Message, state: FSMContext):
    try:
        task_text = message.text.strip()
        if len(task_text) < 10:
            await message.answer("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏—Ç–µ –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏.")
            return

        data = await state.get_data()
        lang = data.get("language", "Python")

        prompt = build_prompt(task_text, language=lang)
        await message.answer("ü§ñ –î—É–º–∞—é –Ω–∞–¥ —Ä–µ—à–µ–Ω–∏–µ–º...")

        result = get_chatgpt_response(prompt)
        await message.answer(f"üì¶ –í–æ—Ç —Ä–µ—à–µ–Ω–∏–µ:\n\n```{lang.lower()}\n{result}\n```")

    except Exception as e:
        await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞.")
        logging.exception(e)

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ===
@dp.message(UserState.waiting_for_task, lambda m: m.document is not None)
async def handle_document(message: Message, state: FSMContext):
    try:
        # 1. –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file_path = await download_file(bot, message.document)
        await message.answer(f"‚úÖ –§–∞–π–ª –ø–æ–ª—É—á–µ–Ω: `{file_path.name}`")

        # 2. –ü–∞—Ä—Å–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        text = extract_text_from_file(file_path)
        if not text or len(text.strip()) < 10:
            await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–ª–∏ –æ–Ω–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ.")
            return

        # 3. –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —è–∑—ã–∫ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        data = await state.get_data()
        language = data.get("language", "Python")

        # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = build_prompt(text, language=language)
        await message.answer("ü§ñ –î—É–º–∞—é –Ω–∞–¥ —Ä–µ—à–µ–Ω–∏–µ–º...")

        # 5. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenAI
        result = get_chatgpt_response(prompt)

        # 6. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥
        await message.answer(f"üì¶ –ì–æ—Ç–æ–≤–æ! –í–æ—Ç —Ä–µ—à–µ–Ω–∏–µ:\n\n```{language.lower()}\n{result}\n```")

    except ValueError as e:
        await message.answer(f"‚ö†Ô∏è {e}")
    except Exception as e:
        await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞.")
        logging.exception(e)


# === –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ===
async def main():
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...")
    await bot.delete_webhook(drop_pending_updates=True)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())